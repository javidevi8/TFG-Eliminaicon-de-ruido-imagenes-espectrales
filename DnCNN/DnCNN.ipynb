{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9201393-1fa5-4aa8-b46c-7329da13e706",
   "metadata": {},
   "source": [
    "# Modelo DnCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94986b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from skimage.util import random_noise\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48e9ace-999d-43f6-9bae-c8feb9c7d57d",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ab5af-fb8b-4885-b09a-05b7288ffbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f95b4",
   "metadata": {},
   "source": [
    "## Crear imagenes con mas ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe725ad-80c5-48ba-813f-c769715cabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método que hace padding alrededor de las imagenes y hace un resice de ellas\n",
    "def pad_resize_image(image, target_shape):\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "    target_height, target_width = target_shape\n",
    "\n",
    "    # Calcular el factor de escala y las nuevas dimensiones\n",
    "    scale = min(target_width / width, target_height / height)\n",
    "    new_width = int(width * scale)\n",
    "    new_height = int(height * scale)\n",
    "\n",
    "    # Redimensionar la imagen\n",
    "    resized_image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "    pad_height = target_height - new_height\n",
    "    pad_width = target_width - new_width\n",
    "    \n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "    \n",
    "    padded_image = cv2.copyMakeBorder(resized_image, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    return padded_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ecfc96-3c68-4829-b4eb-b7eec4e3af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter(image, kernel_size=(5, 5), sigma=4.0):\n",
    "    return cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "\n",
    "# Función para aplicar filtrado bilateral\n",
    "def bilateral_filter(image, d=9, sigma_color=75, sigma_space=75):\n",
    "    return cv2.bilateralFilter(image, d, sigma_color, sigma_space)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089acfe3-fefa-4cc7-88c5-4c6f6e09ae72",
   "metadata": {},
   "source": [
    "### Una de las opcciones de preprocesar. Creamos los datos de entrenamiento añadiendo ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa0c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos los datos\n",
    "filepath = \"./Datos/*\"\n",
    "paths = glob.glob(filepath)\n",
    "\n",
    "#Reordenamos los datos para que no esten segudos los datos de mismas dimensones\n",
    "random.shuffle(paths)\n",
    "separacion = int((len(paths) * 90)/100)\n",
    "train_clean = []\n",
    "train_gaus =  []\n",
    "test_clean = []\n",
    "test_gaus = []\n",
    "\n",
    "#Creamos el size que queremos para las imagenes\n",
    "target_shape = (400, 400) \n",
    "\n",
    "#Recorremos los datos para aplicarles el preprocesado\n",
    "for i in range(len(paths)):\n",
    "    \n",
    "    image = cv2.imread(paths[i])\n",
    "    image = image / 255.0\n",
    "    noisy_image = random_noise(image, mode='gaussian', mean=0, var=0.02) \n",
    "\n",
    "    padded_image = pad_resize_image(image, target_shape)\n",
    "    padded_noisy_image = pad_resize_image(noisy_image, target_shape)\n",
    "    \n",
    "    if i < separacion:\n",
    "        train_clean.append(padded_image)\n",
    "        train_gaus.append(padded_noisy_image)\n",
    "    else:\n",
    "        test_clean.append(padded_image)\n",
    "        test_gaus.append(padded_noisy_image)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e3f1d8-a32b-4e12-b982-52623c2f873b",
   "metadata": {},
   "source": [
    "### Una de las opcciones de preprocesar. Creamos los datos target suavizando la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71165f-3dc0-4096-b0bb-c769ad879f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos los datos\n",
    "filepath = \"./Datos/*\"\n",
    "paths = glob.glob(filepath)\n",
    "\n",
    "#Reordenamos los datos para que no esten segudos los datos de mismas dimensones\n",
    "random.shuffle(paths)\n",
    "separacion = int((len(paths) * 90)/100)\n",
    "train_clean = []\n",
    "train_gaus =  []\n",
    "test_clean = []\n",
    "test_gaus = []\n",
    "\n",
    "#Creamos el size que queremos para las imagenes\n",
    "target_shape = (400, 400) \n",
    "\n",
    "#Recorremos los datos para aplicarles el preprocesado\n",
    "for i in range(len(paths)):\n",
    "    \n",
    "    image = cv2.imread(paths[i])\n",
    "    image = image / 255.0\n",
    "\n",
    "    clean_image = gaussian_filter(image)\n",
    "    \n",
    "    padded_image = pad_resize_image(clean_image, target_shape)\n",
    "    padded_noisy_image = pad_resize_image(image, target_shape)\n",
    "    \n",
    "    if i < separacion:\n",
    "        train_clean.append(padded_image)\n",
    "        train_gaus.append(padded_noisy_image)\n",
    "    else:\n",
    "        test_clean.append(padded_image)\n",
    "        test_gaus.append(padded_noisy_image)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3027e610-fd8a-401d-8561-a933199160dd",
   "metadata": {},
   "source": [
    "## Visualizamos las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "#Mostrar un ejemplo de las imagenes\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(train_clean[0])\n",
    "plt.axis('off')\n",
    "plt.title('Train clean')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(train_gaus[0])\n",
    "plt.axis('off')\n",
    "plt.title('Train gaus')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e868e3-7adf-42d0-8a4d-6e0152a09402",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_clean[0])\n",
    "plt.axis('off')\n",
    "plt.title('Test clean')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_gaus[0])\n",
    "plt.axis('off')\n",
    "plt.title('Test gaus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d61763-ca33-4a36-8859-bcdfa3a24ec0",
   "metadata": {},
   "source": [
    "## Aplanamos los datos\n",
    "Esto lo hacemos porque el modelo acepta un solo tensor de datos y no se le puede pasar la lista entera de imágenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba667b4-1298-4dd6-9352-beb7cef0daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = np.array(train_clean)\n",
    "train_gaus = np.array(train_gaus)\n",
    "test_clean = np.array(test_clean)\n",
    "test_gaus = np.array(test_gaus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5f8a7",
   "metadata": {},
   "source": [
    "# Creación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Subtract\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint,LearningRateScheduler\n",
    "\n",
    "\n",
    "class DnCnn():\n",
    "    \n",
    "    #Iniciamos la clase del modelo\n",
    "    def __init__(self,num_filters=64,output_channels=3,depth = 20,model_name=\"DnCnn_TFG1\"):\n",
    "        \n",
    "        self.num_filters = num_filters\n",
    "        self.output_channels = output_channels\n",
    "        self.depth = depth\n",
    "        self.model_name = model_name\n",
    "        self.decay_factor = 0\n",
    "\n",
    "        self.model = self.build_DnCnn()\n",
    "        self.model.compile(optimizer='adam', loss='mae')\n",
    "        \n",
    "        self.model.summary()\n",
    "\n",
    "    #Funcion que construye el modelo\n",
    "    def build_DnCnn(self,input_shape=(None,None,3)):\n",
    "        \n",
    "        inputs = Input(shape=input_shape)\n",
    "        \n",
    "        # Primera capa convolucional con activación ReLU\n",
    "        output = Conv2D(self.num_filters, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    \n",
    "        # Capas intermedias con Conv2D + BatchNormalization + ReLU\n",
    "        for _ in range(2, self.depth):\n",
    "            output = Conv2D(self.num_filters, (3, 3), padding='same', use_bias=False)(output)\n",
    "            output = BatchNormalization()(output)\n",
    "            output = relu(output)\n",
    "\n",
    "        # Capa final sin activación\n",
    "        output = Conv2D(self.output_channels, (3, 3), padding='same', use_bias=False)(output)\n",
    "    \n",
    "        # Restamos la entrada de la salida para obtener el resultado final\n",
    "        output = Subtract()([inputs, output])\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=output)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    def ajuste_learning_rate(self,epochs,lr_inicial):\n",
    "        \n",
    "        #calculamos el lr final que buscamos\n",
    "        final_lr = lr_inicial/1000\n",
    "        \n",
    "        #Calculamos cuanto tiene que bajar cada vez\n",
    "        #Explicacion de la linea: \n",
    "        #(a donde quiero llegar / donde empiezo) elevado (cuannto avanzo por paso/en cuantos pasostengo para hacerlo)\n",
    "        self.decay_factor = (final_lr / lr_inicial) ** (1.0 / epochs)\n",
    "\n",
    "\n",
    "    def lr_scheduler(self,epoch, lr):\n",
    "        #se calcula el learning rate para la siguiente época\n",
    "        new_lr = lr * self.decay_factor\n",
    "        return new_lr\n",
    "\n",
    "    \n",
    "    \n",
    "    def train(self, X_train, y_train, batch_size,epoch, lr):\n",
    "        # Callbacks\n",
    "        tensorboard_cb = TensorBoard(log_dir='./logs8/fit',\n",
    "        histogram_freq=1,\n",
    "        write_graph=True,\n",
    "        write_images=True,\n",
    "        update_freq=\"epoch\"\n",
    "        )\n",
    "\n",
    "        path = os.path.join(\"./checkpoints/\" + self.model_name +\".keras\")\n",
    "        checkpoint_cb = ModelCheckpoint(filepath=path, save_best_only=True)\n",
    "        \n",
    "        self.ajuste_learning_rate(epoch,lr)\n",
    "        \n",
    "        # Creamos el callback de LearningRateScheduler\n",
    "        lr_callback = LearningRateScheduler(self.lr_scheduler) \n",
    "\n",
    "        \n",
    "        # Entrenamos el modelo\n",
    "        history = self.model.fit(X_train, y_train,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epoch,\n",
    "               callbacks=[tensorboard_cb, checkpoint_cb, lr_callback],\n",
    "               validation_split=0.2)\n",
    "\n",
    "        print(\"Entrenamiento finalizado.\")\n",
    "        return history\n",
    "\n",
    "    def save(self,nombre):\n",
    "        self.model.save(nombre)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8385b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializamos el modelo\n",
    "model = DnCnn(model_name = \"DnCNN_TFG_prueba_gaus_mae\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f6075-38a5-41f4-9616-0d543b533454",
   "metadata": {},
   "source": [
    "# Creamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.train(train_gaus,train_clean,16,10,0.001)\n",
    "model.save(\"DnCNN_TFG_prueba_gaus_mae.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485efa39-2d1e-4cb3-a4e4-26bf4ed7df90",
   "metadata": {},
   "source": [
    "# Visualizamos como ha ido el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc39445-dad1-4a27-9588-185ceadb122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.utils import plot_history\n",
    "print(sorted(list(history.history.keys())))\n",
    "plt.figure(figsize=(16,5))\n",
    "plot_history(history,['loss','val_loss']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a2bfc-6890-4756-b819-1b616dfe8f6e",
   "metadata": {},
   "source": [
    "# Visualizacion con Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0eb06-4261-4f77-901a-f599dccfb23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs7/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5284c-9550-48ae-a737-2b5bf75ef33b",
   "metadata": {},
   "source": [
    "# Prediccion de resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbaf897-12cd-4589-b9d9-52198302cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = tf.keras.models.load_model(\"DnCNN_TFG_prueba_gaus_mae.h5\")\n",
    "\n",
    "# Suponiendo que test_gaus[0] es una sola imagen\n",
    "noisy =test_gaus[9][np.newaxis, ...]\n",
    "\n",
    "# Realizar predicciones\n",
    "predictions = model.predict(noisy)\n",
    "\n",
    "predicted_image = np.squeeze(predictions, axis=0)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Imagen original con ruido\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Imagen con Ruido')\n",
    "plt.imshow(test_gaus[9])\n",
    "plt.axis('off')\n",
    "\n",
    "# Imagen original limpia\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Imagen Limpia')\n",
    "plt.imshow(predicted_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c436a4-a26d-426c-88e2-8c553591dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular PSNR y SSIM\n",
    "def calcular_metricas(original, denoised):\n",
    "    psnr_value = psnr(original, denoised, data_range=original.max() - original.min())\n",
    "    ssim_value = ssim(original, denoised, data_range=original.max() - original.min(), channel_axis=2, win_size=3)\n",
    "    return psnr_value, ssim_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816a491-f07d-486a-8316-28867c1f5cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_base, ssim_base = calcular_metricas(test_gaus[9],predicted_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f0456-2eaa-4cb2-9f9a-69976d8aa83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PSNR: \" + str(psnr_base))\n",
    "print(\"ssim_base: \" + str(ssim_base))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
